# **Large Language Models (LLMs) Testing Framework**

This suite presents a curated set of problems designed explicitly to challenge and evaluate the capabilities of Large Language Models (LLMs) in software engineering scenarios. Unlike conventional coding platforms such as LeetCode that emphasize algorithmic problem-solving, this suite dives into real-world software development challenges, akin to those found in professional settings.

---

## **1. Key Features of This Suite Include:**

- **Production-Grade Application Development:** Each test focuses on the creation of components or solutions that are part of real-world, production-grade applications. It isn't just about writing functional code; it's about writing maintainable, scalable, and efficient code fit for deployment.

- **Automated Solution Verification:** The answers generated by the LLM can be verified using unit tests tailored for each problem. This ensures that the solution isn't merely syntactically correct but functionally sound and meets the predefined requirements.

- **Emphasis on Quality:** The suite assesses the ability to produce high-quality software deliverables. It evaluates best practices, design patterns, and other aspects of software quality.

- **Bridging the Gap to Autonomous Software Development:** The end goal of such evaluations is to determine if LLMs can, one day, autonomously handle complex software engineering tasks without human supervision. Achieving proficiency in these tests indicates a significant leap towards that future, where LLMs could potentially orchestrate entire software projects or even spawn software companies autonomously.

This suite is a step towards understanding and harnessing the potential of LLMs in the vast landscape of software engineering, pushing the boundaries of autonomous artificial intelligence in real-world applications.

---
## **2. How to Run the Application**

### a. Setup:
- Prepare your development environment ensuring you have the necessary software tools installed, including Python and pip (Python's package installer).
- It's advisable to work within a virtual environment to manage dependencies for your project and ensure its requirements are isolated from the global environment.

### b. Creating a Virtual Environment:
- Open a terminal and navigate to the project directory.
- Run the following command to create a virtual environment named `venv` (you can name it anything you prefer):
    ```bash
    python3 -m venv venv
    ```
- This will create a virtual environment in the project directory which will help to keep dependencies required by different projects separate.

### c. Activating the Virtual Environment:
- To activate the virtual environment, run:
    ```bash
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```
- Once activated, the virtual environment will isolate your Python environment from the global environment.

### d. Installing Dependencies:
- With the virtual environment activated, you can now install the project's dependencies using pip. Run:
    ```bash
    pip install -r requirements.txt
    ```
- This will install all the necessary dependencies listed in the `requirements.txt` file.

### e. Running the Application:
- Now that the dependencies are installed, you can run the application by executing the following command:
    ```bash
    python -m main.py
    ```
---

## **3. Novelty of the Benchmark**

Traditional coding challenges, like those seen on platforms such as LeetCode, emphasize algorithmic thinking and problem-solving in isolation. In contrast, this benchmark:

- **Real-world Scenarios:** Models challenges that mirror real-world software development and system design issues.
- **Emphasis on Quality:** Focuses not just on solving a problem but on how it's solved, ensuring the solution is production-ready.
- **Diverse Software Engineering Aspects:** Covers various fields such as system design, microservices, database optimization, and more, providing a holistic assessment.
- **Automated Evaluation:** Uses automated testing and scoring to provide objective feedback on the solutions.
